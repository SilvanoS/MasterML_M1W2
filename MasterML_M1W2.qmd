---
title: "Machine Learning Overview"
author: "Prof.ssa Ileana Baldi<br>UBEP<br>"
format: 
  revealjs:
    self-contained: true
    transition: fade
    transition-speed: slow
    #slide-number: true
    #footer: "[Master UBEP Web Page](https://www.unipd-ubep.it/masters/machine-learning-and-big-data/)&nbsp;&nbsp;&nbsp;"
    theme: [moon, custom_ss.scss]
    preview-links: auto
    chalkboard: false
      
from: markdown+emoji
execute:
  echo: true
---

## Course Outline week 2

<br/>

**Machine learning overview**

::: incremental
1.  Performance assessment
    -   model evaluation
    -   model selection
2.  Resampling methods
    -   Cross-validation
    -   Bootstrap
:::


## Performance assessment

::: {.absolute top="20%" left="25%"}



Loss functions for numerical ouput:

$$
L(Y,\hat{f}(X))=\begin{cases} 
|Y-\hat{f}(X)| \\ 
(Y-\hat{f}(X))^2 
\end{cases}
$$  

Loss functions for categorical ouput:
$$
L(Y,\hat{f}(X))=\begin{cases} 
I(Y \ne\hat{f}(X)) \\ 
-2{log(\hat p_k(X))}
\end{cases}
$$

:::


## Test vs training error rate


::: {style="font-size: 70%;"}

- _Training error rate_ is simply the average error from a statistical learning method that uses predictions based on the data that was used to fit the model in the first place:

$$\frac 1 n \sum_{i=1}^n L(y_i,\hat{f}(x_i))$$

- \textcolor {blue}{\emph{Test error rate}} is the average error from using a statistical learning method to predict the response on a _new_ observation:

$$\mathit{E}(L(Y,\hat{f}(X))$$


:::


::: {style="font-size: 40%;"}
::: {.absolute top="80%" left="25%"}

(qui metto la referenza sulle formule)
:::
:::



# Big Data 2

::: {.absolute top="0" left="100%"}
::: sectionhead
1 [2 3 4]{style="opacity:0.25"}
:::
:::

------------------------------------------------------------------------
